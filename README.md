# ðŸŽ­ Facial Emotion Recognition (FER) using DCNN

This repository contains a **Deep Convolutional Neural Network (DCNN)** designed to identify and classify human emotions from facial images. Using the **FER2013 dataset**, the model processes **48Ã—48 grayscale images** to predict one of seven emotional states.

---

## ðŸ› ï¸ Tech Stack

- ðŸ **Python** â€“ Core programming language  
- ðŸ§  **TensorFlow / Keras** â€“ Deep learning framework and model construction  
- ðŸ“Š **Pandas & NumPy** â€“ Data wrangling and numerical processing  
- ðŸŽ¨ **Matplotlib & Seaborn** â€“ Data visualization and performance plotting  
- ðŸ§ª **Scikit-learn** â€“ Data preprocessing and evaluation metrics  
- ðŸ–¼ï¸ **ImageDataGenerator** â€“ Real-time image augmentation  

---

## ðŸ—ï¸ Model Architecture

The model uses a structured deep architecture with **2.3M+ parameters** to capture complex facial features.

| Layer Block        | Configuration            | Purpose |
|--------------------|--------------------------|----------|
| **Input**          | (48, 48, 1)              | Grayscale pixel data |
| **Conv Block 1**   | 64 Filters (5Ã—5)         | Basic edge & texture detection |
| **Conv Block 2**   | 128 Filters (3Ã—3)        | Facial part identification (eyes, nose, mouth) |
| **Conv Block 3**   | 256 Filters (3Ã—3)        | Complex facial expression patterns |
| **Normalization**  | BatchNormalization       | Stabilizes training & speeds up convergence |
| **Regularization** | Dropout (0.4 â€“ 0.6)      | Prevents overfitting |
| **Output**         | Dense + Softmax          | Probability distribution across 7 emotions |

---

## ðŸ“ˆ Performance Analysis

### ðŸ”¹ Training Dynamics
- Optimizer used: **Nadam**
- `ReduceLROnPlateau` callback reduces learning rate by 50% when performance plateaus.
- Around **Epoch 38**, learning rate reduction significantly improved validation accuracy.
- Early stopping prevents unnecessary training once convergence is achieved.

### ðŸ”¹ Accuracy
- Achieved **~66% validation accuracy**
- Human-level accuracy on FER2013 is estimated at **~65%**, making this a competitive result.

### ðŸ”¹ Class Distribution Insights
- âœ… **Strong Performance**: Happy ðŸ˜Š and Surprise ðŸ˜²  
- âš ï¸ **Challenging Classes**: Sad ðŸ˜¢ vs Neutral ðŸ˜  

---

## ðŸ’¡ Conclusion

While the FER2013 dataset is notoriously difficult due to lighting variations and "in-the-wild" facial orientations, the combination of:

- **ELU activations**
- **Batch Normalization**
- **Aggressive Dropout**
- **Learning rate scheduling**

creates a robust and competitive classifier.

This project demonstrates that deep learning can effectively interpret human emotions even within the constraints of low-resolution **48Ã—48 grayscale imagery**. ðŸš€

---

## ðŸš€ How to Run

### 1ï¸âƒ£ Prepare Data
Place your `fer2013.csv` file inside the project directory.

### 2ï¸âƒ£ Install Dependencies
`bash
pip install tensorflow pandas numpy matplotlib seaborn scikit-learn

### 3ï¸âƒ£ Train the Model
python train.py
###4ï¸âƒ£ Callbacks
- ðŸ’¾ Best model automatically saved as best_model.keras
- â¹ï¸ EarlyStopping enabled
- ðŸ“‰ ReduceLROnPlateau for dynamic learning rate adjustment
###5ï¸âƒ£ Visualization
- After training:
- Check performance_dist.png for violin plot analysis of model stability.
---
###ðŸ“‚ Project Structure
FER-DCNN/
- â”‚
- â”œâ”€â”€ train.py
- â”œâ”€â”€ best_model.keras
- â”œâ”€â”€ performance_dist.png
- â”œâ”€â”€ fer2013.csv
- â””â”€â”€ README.md
---
###ðŸ”® Future Improvements

- Real-time webcam emotion detection

- Transfer learning with pretrained CNN backbones

- Hyperparameter tuning for improved generalization

- Model deployment using Flask / Streamlit
---
## ðŸ’¡ Conclusion

- Facial Emotion Recognition using Deep Convolutional Neural Networks demonstrates how deep learning can interpret subtle human expressions even under constrained conditions such as low-resolution (48Ã—48) grayscale imagery.

- Despite the inherent challenges of the FER2013 dataset â€” including lighting variations, occlusions, and real-world facial orientations â€” this model achieves competitive validation accuracy through a carefully designed architecture, effective regularization, and adaptive learning rate scheduling.

- The results highlight how structured convolutional layers progressively learn from basic edges to complex emotional patterns, proving that with the right optimization strategies, machine learning systems can approach human-level performance in affect recognition.

- This project not only strengthens practical understanding of CNN architectures but also showcases the real-world applicability of deep learning in emotion-aware systems, human-computer interaction, and AI-driven analytics.

---
## 
> "When machines learn to read emotions, they donâ€™t just classify faces â€” they begin to understand the language of human expression."
